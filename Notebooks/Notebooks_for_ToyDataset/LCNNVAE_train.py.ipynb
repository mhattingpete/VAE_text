{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train script for Ladder VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../Modules\")\n",
    "sys.path.append(\"../../Datasets\")\n",
    "\n",
    "# local imports\n",
    "from train import train\n",
    "from helpers import nll_loss\n",
    "from models import LadderCNNVAE\n",
    "from ToyDatasets.timeSeries import Sinusoids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_steps = 16\n",
    "dataset_size = 5000\n",
    "num_classes = 10\n",
    "\n",
    "data_loader = DataLoader(Sinusoids(num_steps,virtual_size=dataset_size,quantization=num_classes),batch_size=batch_size,shuffle=True)\n",
    "valid_data_loader = DataLoader(Sinusoids(num_steps,virtual_size=dataset_size,quantization=num_classes),batch_size=batch_size,shuffle=True)\n",
    "\n",
    "batch_loader = iter(data_loader)\n",
    "valid_batch_loader = iter(valid_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters 761770\n",
      "Forward pass succesfull\n"
     ]
    }
   ],
   "source": [
    "model = LadderCNNVAE(input_size=1,hidden_sizes=[256,128,64],latent_sizes=[64,32,16],recon_hidden_size=256,output_size=num_classes,use_softmax=True)\n",
    "print(\"Number of trainable parameters {}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "# test forward pass\n",
    "try:\n",
    "    initial_batch = batch_loader.next()\n",
    "    x = Variable(initial_batch).type(torch.FloatTensor).transpose(1,0)\n",
    "    test,_ = model(x)\n",
    "    assert (test.shape[0] == x.shape[0] and test.shape[1] == x.shape[1] and test.shape[2] == num_classes)\n",
    "    print(\"Forward pass succesfull\")\n",
    "except:\n",
    "    print(\"Error in forward pass. Output should have shape: {} but had {}\".format(x.contiguous().view(-1).shape,test.view(-1).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate,weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"min\",factor=0.5,verbose=True,cooldown=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train (1 2%) elbo: -1.8537 r_loss: -1.8537 kl: 385.2183 aux_loss: 0.0000 beta 0.00e+00\n",
      "Valid (1 2%) elbo: -1.5330 r_loss: -1.5330 kl: 651.9501 aux_loss: 0.0000 beta 0.00e+00\n",
      "\n",
      "Train (2 4%) elbo: -1.4763 r_loss: -1.4213 kl: 269.2520 aux_loss: 0.0000 beta 2.04e-04\n",
      "Valid (2 4%) elbo: -1.3451 r_loss: -1.3050 kl: 196.6461 aux_loss: 0.0000 beta 2.04e-04\n",
      "\n",
      "Train (3 6%) elbo: -1.3224 r_loss: -1.2580 kl: 157.7473 aux_loss: 0.0000 beta 4.08e-04\n",
      "Valid (3 6%) elbo: -1.2061 r_loss: -1.1486 kl: 140.7940 aux_loss: 0.0000 beta 4.08e-04\n",
      "\n",
      "Train (4 8%) elbo: -1.2484 r_loss: -1.1730 kl: 123.0725 aux_loss: 0.0000 beta 6.12e-04\n",
      "Valid (4 8%) elbo: -1.1830 r_loss: -1.1074 kl: 123.4138 aux_loss: 0.0000 beta 6.12e-04\n",
      "\n",
      "Train (5 10%) elbo: -1.1879 r_loss: -1.1010 kl: 106.4352 aux_loss: 0.0000 beta 8.16e-04\n",
      "Valid (5 10%) elbo: -1.2314 r_loss: -1.1445 kl: 106.4605 aux_loss: 0.0000 beta 8.16e-04\n",
      "\n",
      "Train (6 12%) elbo: -1.1528 r_loss: -1.0526 kl: 98.1491 aux_loss: 0.0000 beta 1.02e-03\n",
      "Valid (6 12%) elbo: -0.9676 r_loss: -0.8631 kl: 102.4689 aux_loss: 0.0000 beta 1.02e-03\n",
      "\n",
      "Train (7 14%) elbo: -1.1281 r_loss: -1.0159 kl: 91.5784 aux_loss: 0.0000 beta 1.22e-03\n",
      "Valid (7 14%) elbo: -0.9791 r_loss: -0.8698 kl: 89.2145 aux_loss: 0.0000 beta 1.22e-03\n",
      "\n",
      "Train (8 16%) elbo: -1.0960 r_loss: -0.9767 kl: 83.5027 aux_loss: 0.0000 beta 1.43e-03\n",
      "Valid (8 16%) elbo: -1.0297 r_loss: -0.9198 kl: 76.9582 aux_loss: 0.0000 beta 1.43e-03\n",
      "\n",
      "Train (9 18%) elbo: -1.0892 r_loss: -0.9615 kl: 78.2181 aux_loss: 0.0000 beta 1.63e-03\n",
      "Valid (9 18%) elbo: -0.9337 r_loss: -0.7978 kl: 83.2369 aux_loss: 0.0000 beta 1.63e-03\n",
      "\n",
      "Train (10 20%) elbo: -1.0665 r_loss: -0.9307 kl: 73.9335 aux_loss: 0.0000 beta 1.84e-03\n",
      "Valid (10 20%) elbo: -0.9315 r_loss: -0.8008 kl: 71.1285 aux_loss: 0.0000 beta 1.84e-03\n",
      "\n",
      "Train (11 22%) elbo: -1.0548 r_loss: -0.9121 kl: 69.9084 aux_loss: 0.0000 beta 2.04e-03\n",
      "Valid (11 22%) elbo: -0.9431 r_loss: -0.7682 kl: 85.6995 aux_loss: 0.0000 beta 2.04e-03\n",
      "\n",
      "Train (12 24%) elbo: -1.0681 r_loss: -0.9140 kl: 68.6451 aux_loss: 0.0000 beta 2.24e-03\n",
      "Valid (12 24%) elbo: -1.0974 r_loss: -0.9492 kl: 66.0068 aux_loss: 0.0000 beta 2.24e-03\n",
      "\n",
      "Train (13 26%) elbo: -1.0495 r_loss: -0.8877 kl: 66.0336 aux_loss: 0.0000 beta 2.45e-03\n",
      "Valid (13 26%) elbo: -0.9429 r_loss: -0.8007 kl: 58.0751 aux_loss: 0.0000 beta 2.45e-03\n",
      "\n",
      "Train (14 28%) elbo: -1.0360 r_loss: -0.8681 kl: 63.2817 aux_loss: 0.0000 beta 2.65e-03\n",
      "Valid (14 28%) elbo: -0.9384 r_loss: -0.7744 kl: 61.8373 aux_loss: 0.0000 beta 2.65e-03\n",
      "\n",
      "Train (15 30%) elbo: -1.0489 r_loss: -0.8707 kl: 62.3743 aux_loss: 0.0000 beta 2.86e-03\n",
      "Valid (15 30%) elbo: -1.0808 r_loss: -0.9203 kl: 56.1679 aux_loss: 0.0000 beta 2.86e-03\n",
      "\n",
      "Train (16 32%) elbo: -1.0445 r_loss: -0.8590 kl: 60.6116 aux_loss: 0.0000 beta 3.06e-03\n",
      "Valid (16 32%) elbo: -0.9132 r_loss: -0.7193 kl: 63.3466 aux_loss: 0.0000 beta 3.06e-03\n",
      "\n",
      "Train (17 34%) elbo: -1.0529 r_loss: -0.8608 kl: 58.8297 aux_loss: 0.0000 beta 3.27e-03\n",
      "Valid (17 34%) elbo: -1.0578 r_loss: -0.8700 kl: 57.5194 aux_loss: 0.0000 beta 3.27e-03\n",
      "\n",
      "Train (18 36%) elbo: -1.0597 r_loss: -0.8599 kl: 57.5932 aux_loss: 0.0000 beta 3.47e-03\n",
      "Valid (18 36%) elbo: -1.0755 r_loss: -0.8807 kl: 56.1487 aux_loss: 0.0000 beta 3.47e-03\n",
      "\n",
      "Train (19 38%) elbo: -1.0371 r_loss: -0.8300 kl: 56.3738 aux_loss: 0.0000 beta 3.67e-03\n",
      "Valid (19 38%) elbo: -0.9477 r_loss: -0.7582 kl: 51.5957 aux_loss: 0.0000 beta 3.67e-03\n",
      "\n",
      "Train (20 40%) elbo: -1.0418 r_loss: -0.8288 kl: 54.9249 aux_loss: 0.0000 beta 3.88e-03\n",
      "Valid (20 40%) elbo: -0.8707 r_loss: -0.6542 kl: 55.8317 aux_loss: 0.0000 beta 3.88e-03\n",
      "\n",
      "Train (21 42%) elbo: -1.0475 r_loss: -0.8292 kl: 53.4996 aux_loss: 0.0000 beta 4.08e-03\n",
      "Valid (21 42%) elbo: -0.9887 r_loss: -0.7833 kl: 50.3387 aux_loss: 0.0000 beta 4.08e-03\n",
      "\n",
      "Train (22 44%) elbo: -1.0315 r_loss: -0.8062 kl: 52.5722 aux_loss: 0.0000 beta 4.29e-03\n",
      "Valid (22 44%) elbo: -0.9346 r_loss: -0.7233 kl: 49.2964 aux_loss: 0.0000 beta 4.29e-03\n",
      "\n",
      "Train (23 46%) elbo: -1.0410 r_loss: -0.8126 kl: 50.8652 aux_loss: 0.0000 beta 4.49e-03\n",
      "Valid (23 46%) elbo: -0.9012 r_loss: -0.6654 kl: 52.5236 aux_loss: 0.0000 beta 4.49e-03\n",
      "\n",
      "Train (24 48%) elbo: -1.0365 r_loss: -0.8038 kl: 49.5769 aux_loss: 0.0000 beta 4.69e-03\n",
      "Valid (24 48%) elbo: -0.9528 r_loss: -0.7352 kl: 46.3569 aux_loss: 0.0000 beta 4.69e-03\n",
      "\n",
      "Train (25 50%) elbo: -1.0163 r_loss: -0.7791 kl: 48.4203 aux_loss: 0.0000 beta 4.90e-03\n",
      "Valid (25 50%) elbo: -0.8754 r_loss: -0.6438 kl: 47.2859 aux_loss: 0.0000 beta 4.90e-03\n",
      "\n",
      "Train (26 52%) elbo: -1.0192 r_loss: -0.7779 kl: 47.2819 aux_loss: 0.0000 beta 5.10e-03\n",
      "Valid (26 52%) elbo: -0.9270 r_loss: -0.6727 kl: 49.8277 aux_loss: 0.0000 beta 5.10e-03\n",
      "\n",
      "Train (27 54%) elbo: -1.0164 r_loss: -0.7716 kl: 46.1354 aux_loss: 0.0000 beta 5.31e-03\n",
      "Valid (27 54%) elbo: -0.8885 r_loss: -0.6671 kl: 41.7348 aux_loss: 0.0000 beta 5.31e-03\n",
      "\n",
      "Train (28 56%) elbo: -1.0059 r_loss: -0.7608 kl: 44.4951 aux_loss: 0.0000 beta 5.51e-03\n",
      "Valid (28 56%) elbo: -0.8235 r_loss: -0.5662 kl: 46.7031 aux_loss: 0.0000 beta 5.51e-03\n",
      "\n",
      "Train (29 57%) elbo: -1.0019 r_loss: -0.7550 kl: 43.2089 aux_loss: 0.0000 beta 5.71e-03\n",
      "Valid (29 57%) elbo: -0.8967 r_loss: -0.6651 kl: 40.5243 aux_loss: 0.0000 beta 5.71e-03\n",
      "\n",
      "Train (30 60%) elbo: -0.9886 r_loss: -0.7380 kl: 42.3455 aux_loss: 0.0000 beta 5.92e-03\n",
      "Valid (30 60%) elbo: -0.9527 r_loss: -0.7388 kl: 36.1380 aux_loss: 0.0000 beta 5.92e-03\n",
      "\n",
      "Train (31 62%) elbo: -0.9866 r_loss: -0.7371 kl: 40.7446 aux_loss: 0.0000 beta 6.12e-03\n",
      "Valid (31 62%) elbo: -0.8665 r_loss: -0.6277 kl: 39.0042 aux_loss: 0.0000 beta 6.12e-03\n",
      "\n",
      "Train (32 64%) elbo: -0.9607 r_loss: -0.7089 kl: 39.8050 aux_loss: 0.0000 beta 6.33e-03\n",
      "Valid (32 64%) elbo: -0.8934 r_loss: -0.6491 kl: 38.6160 aux_loss: 0.0000 beta 6.33e-03\n",
      "\n",
      "Train (33 66%) elbo: -0.9627 r_loss: -0.7056 kl: 39.3763 aux_loss: 0.0000 beta 6.53e-03\n",
      "Valid (33 66%) elbo: -0.9460 r_loss: -0.7076 kl: 36.5045 aux_loss: 0.0000 beta 6.53e-03\n",
      "\n",
      "Train (34 68%) elbo: -0.9462 r_loss: -0.6899 kl: 38.0605 aux_loss: 0.0000 beta 6.73e-03\n",
      "Valid (34 68%) elbo: -0.8062 r_loss: -0.5543 kl: 37.4077 aux_loss: 0.0000 beta 6.73e-03\n",
      "\n",
      "Train (35 70%) elbo: -0.9574 r_loss: -0.6970 kl: 37.5193 aux_loss: 0.0000 beta 6.94e-03\n",
      "Valid (35 70%) elbo: -0.8465 r_loss: -0.5935 kl: 36.4657 aux_loss: 0.0000 beta 6.94e-03\n",
      "\n",
      "Train (36 72%) elbo: -0.9752 r_loss: -0.7137 kl: 36.6126 aux_loss: 0.0000 beta 7.14e-03\n",
      "Valid (36 72%) elbo: -0.8877 r_loss: -0.6195 kl: 37.5457 aux_loss: 0.0000 beta 7.14e-03\n",
      "\n",
      "Train (37 74%) elbo: -0.9551 r_loss: -0.6910 kl: 35.9397 aux_loss: 0.0000 beta 7.35e-03\n",
      "Valid (37 74%) elbo: -0.9000 r_loss: -0.6323 kl: 36.4367 aux_loss: 0.0000 beta 7.35e-03\n",
      "\n",
      "Train (38 76%) elbo: -0.9444 r_loss: -0.6772 kl: 35.3743 aux_loss: 0.0000 beta 7.55e-03\n",
      "Valid (38 76%) elbo: -0.8440 r_loss: -0.5786 kl: 35.1404 aux_loss: 0.0000 beta 7.55e-03\n",
      "\n",
      "Train (39 78%) elbo: -0.9338 r_loss: -0.6630 kl: 34.9255 aux_loss: 0.0000 beta 7.76e-03\n",
      "Valid (39 78%) elbo: -0.8627 r_loss: -0.5910 kl: 35.0327 aux_loss: 0.0000 beta 7.76e-03\n",
      "\n",
      "Train (40 80%) elbo: -0.9521 r_loss: -0.6750 kl: 34.8183 aux_loss: 0.0000 beta 7.96e-03\n",
      "Valid (40 80%) elbo: -0.9273 r_loss: -0.6606 kl: 33.5160 aux_loss: 0.0000 beta 7.96e-03\n",
      "\n",
      "Train (41 82%) elbo: -0.9180 r_loss: -0.6348 kl: 34.6945 aux_loss: 0.0000 beta 8.16e-03\n",
      "Valid (41 82%) elbo: -0.7935 r_loss: -0.5239 kl: 33.0245 aux_loss: 0.0000 beta 8.16e-03\n",
      "\n",
      "Train (42 84%) elbo: -0.9274 r_loss: -0.6393 kl: 34.4330 aux_loss: 0.0000 beta 8.37e-03\n",
      "Valid (42 84%) elbo: -0.9272 r_loss: -0.6330 kl: 35.1613 aux_loss: 0.0000 beta 8.37e-03\n",
      "\n",
      "Train (43 86%) elbo: -0.9257 r_loss: -0.6317 kl: 34.3055 aux_loss: 0.0000 beta 8.57e-03\n",
      "Valid (43 86%) elbo: -0.9512 r_loss: -0.6455 kl: 35.6630 aux_loss: 0.0000 beta 8.57e-03\n",
      "\n",
      "Train (44 88%) elbo: -0.9159 r_loss: -0.6157 kl: 34.2089 aux_loss: 0.0000 beta 8.78e-03\n",
      "Valid (44 88%) elbo: -0.8052 r_loss: -0.4891 kl: 36.0161 aux_loss: 0.0000 beta 8.78e-03\n",
      "\n",
      "Train (45 90%) elbo: -0.9271 r_loss: -0.6182 kl: 34.4054 aux_loss: 0.0000 beta 8.98e-03\n",
      "Valid (45 90%) elbo: -0.8702 r_loss: -0.5830 kl: 31.9892 aux_loss: 0.0000 beta 8.98e-03\n",
      "\n",
      "Train (46 92%) elbo: -0.9380 r_loss: -0.6264 kl: 33.9364 aux_loss: 0.0000 beta 9.18e-03\n",
      "Valid (46 92%) elbo: -0.9608 r_loss: -0.6643 kl: 32.2821 aux_loss: 0.0000 beta 9.18e-03\n",
      "\n",
      "Train (47 94%) elbo: -0.9269 r_loss: -0.6090 kl: 33.8681 aux_loss: 0.0000 beta 9.39e-03\n",
      "Valid (47 94%) elbo: -0.8667 r_loss: -0.5547 kl: 33.2285 aux_loss: 0.0000 beta 9.39e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train (48 96%) elbo: -0.9339 r_loss: -0.6089 kl: 33.8763 aux_loss: 0.0000 beta 9.59e-03\n",
      "Valid (48 96%) elbo: -0.8460 r_loss: -0.5335 kl: 32.5802 aux_loss: 0.0000 beta 9.59e-03\n",
      "\n",
      "Train (49 98%) elbo: -0.9451 r_loss: -0.6164 kl: 33.5470 aux_loss: 0.0000 beta 9.80e-03\n",
      "Valid (49 98%) elbo: -0.9166 r_loss: -0.5847 kl: 33.8831 aux_loss: 0.0000 beta 9.80e-03\n",
      "\n",
      "Train (50 100%) elbo: -0.9355 r_loss: -0.6009 kl: 33.4593 aux_loss: 0.0000 beta 1.00e-02\n",
      "Valid (50 100%) elbo: -0.8938 r_loss: -0.5746 kl: 31.9250 aux_loss: 0.0000 beta 1.00e-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use at least 50 iterations to get good results\n",
    "train(data_loader,valid_data_loader,model,optimizer,scheduler,loss_fn=nll_loss,kl_loss_fn=None,n_iters=50,use_softmax=True,max_beta=1e-2,print_every=1,plot_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(),\"../../Saved_models/ToyDataset/LadderCNNVAE_nll_best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model results:\n",
    "\n",
    "### Model 1\n",
    "with the following settings: \n",
    "\n",
    "hidden_sizes=[256,128,64], latent_sizes=[64,32,16], recon_hidden_size=256, with 761770 trainable parameters\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
