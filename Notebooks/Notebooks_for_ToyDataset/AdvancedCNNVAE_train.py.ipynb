{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train script for Advanced CNN VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../Modules\")\n",
    "sys.path.append(\"../../Datasets\")\n",
    "\n",
    "# local imports\n",
    "from train import train\n",
    "from helpers import kl_loss,nll_loss,mse_loss,kl_loss_multi\n",
    "from models import AdvancedCNNVAE\n",
    "from ToyDatasets.timeSeries import Sinusoids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_steps = 16\n",
    "dataset_size = 5000\n",
    "num_classes = 10\n",
    "\n",
    "data_loader = DataLoader(Sinusoids(num_steps,virtual_size=dataset_size,quantization=num_classes),batch_size=batch_size,shuffle=True)\n",
    "valid_data_loader = DataLoader(Sinusoids(num_steps,virtual_size=dataset_size,quantization=num_classes),batch_size=batch_size,shuffle=True)\n",
    "\n",
    "batch_loader = iter(data_loader)\n",
    "valid_batch_loader = iter(valid_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters 845706\n",
      "Forward pass succesfull\n"
     ]
    }
   ],
   "source": [
    "model = AdvancedCNNVAE(input_size=1,conv_size=256,latent_size=64,output_size=num_classes,use_softmax=True)\n",
    "print(\"Number of trainable parameters {}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "# test forward pass\n",
    "try:\n",
    "    initial_batch = batch_loader.next()\n",
    "    x = Variable(initial_batch).type(torch.FloatTensor).transpose(1,0)\n",
    "    test,_ = model(x)\n",
    "    assert (test.shape[0] == x.shape[0] and test.shape[1] == x.shape[1] and test.shape[2] == num_classes)\n",
    "    print(\"Forward pass succesfull\")\n",
    "except:\n",
    "    print(\"Error in forward pass. Output should have shape: {} but had {}\".format(x.contiguous().view(-1).shape,test.view(-1).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate,weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"min\",factor=0.5,verbose=True,cooldown=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train (1 2%) elbo: -1.1175 r_loss: -1.1175 kl: 6725.3170 aux_loss: 0.0000 beta 0.00e+00\n",
      "Valid (1 2%) elbo: -0.4284 r_loss: -0.4284 kl: 22166.7910 aux_loss: 0.0000 beta 0.00e+00\n",
      "\n",
      "Train (2 4%) elbo: -0.8143 r_loss: -0.5240 kl: 1422.4573 aux_loss: 0.0000 beta 2.04e-04\n",
      "Valid (2 4%) elbo: -0.5463 r_loss: -0.4315 kl: 562.3547 aux_loss: 0.0000 beta 2.04e-04\n",
      "\n",
      "Train (3 6%) elbo: -0.5619 r_loss: -0.4165 kl: 356.2132 aux_loss: 0.0000 beta 4.08e-04\n",
      "Valid (3 6%) elbo: -0.6037 r_loss: -0.4746 kl: 316.2652 aux_loss: 0.0000 beta 4.08e-04\n",
      "\n",
      "Train (4 8%) elbo: -0.5495 r_loss: -0.3857 kl: 267.4958 aux_loss: 0.0000 beta 6.12e-04\n",
      "Valid (4 8%) elbo: -0.5465 r_loss: -0.3778 kl: 275.5694 aux_loss: 0.0000 beta 6.12e-04\n",
      "\n",
      "Train (5 10%) elbo: -0.5689 r_loss: -0.3845 kl: 225.8488 aux_loss: 0.0000 beta 8.16e-04\n",
      "Valid (5 10%) elbo: -0.6133 r_loss: -0.4411 kl: 210.9102 aux_loss: 0.0000 beta 8.16e-04\n",
      "\n",
      "Train (6 12%) elbo: -0.5809 r_loss: -0.3804 kl: 196.5178 aux_loss: 0.0000 beta 1.02e-03\n",
      "Valid (6 12%) elbo: -0.6000 r_loss: -0.4068 kl: 189.3445 aux_loss: 0.0000 beta 1.02e-03\n",
      "\n",
      "Train (7 14%) elbo: -0.6023 r_loss: -0.3880 kl: 175.0133 aux_loss: 0.0000 beta 1.22e-03\n",
      "Valid (7 14%) elbo: -0.6197 r_loss: -0.4096 kl: 171.5450 aux_loss: 0.0000 beta 1.22e-03\n",
      "\n",
      "Train (8 16%) elbo: -0.6235 r_loss: -0.3969 kl: 158.6254 aux_loss: 0.0000 beta 1.43e-03\n",
      "Valid (8 16%) elbo: -0.5961 r_loss: -0.3755 kl: 154.4556 aux_loss: 0.0000 beta 1.43e-03\n",
      "\n",
      "Train (9 18%) elbo: -0.6394 r_loss: -0.4057 kl: 143.1052 aux_loss: 0.0000 beta 1.63e-03\n",
      "Valid (9 18%) elbo: -0.6540 r_loss: -0.4237 kl: 141.0527 aux_loss: 0.0000 beta 1.63e-03\n",
      "\n",
      "Train (10 20%) elbo: -0.6535 r_loss: -0.4137 kl: 130.5808 aux_loss: 0.0000 beta 1.84e-03\n",
      "Valid (10 20%) elbo: -0.6128 r_loss: -0.3773 kl: 128.2193 aux_loss: 0.0000 beta 1.84e-03\n",
      "\n",
      "Train (11 22%) elbo: -0.6646 r_loss: -0.4194 kl: 120.1722 aux_loss: 0.0000 beta 2.04e-03\n",
      "Valid (11 22%) elbo: -0.6399 r_loss: -0.4088 kl: 113.2380 aux_loss: 0.0000 beta 2.04e-03\n",
      "\n",
      "Train (12 24%) elbo: -0.6801 r_loss: -0.4294 kl: 111.6754 aux_loss: 0.0000 beta 2.24e-03\n",
      "Epoch    11: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Valid (12 24%) elbo: -0.7613 r_loss: -0.5139 kl: 110.1847 aux_loss: 0.0000 beta 2.24e-03\n",
      "\n",
      "Train (13 26%) elbo: -0.6840 r_loss: -0.4257 kl: 105.4787 aux_loss: 0.0000 beta 2.45e-03\n",
      "Valid (13 26%) elbo: -0.7009 r_loss: -0.4428 kl: 105.3837 aux_loss: 0.0000 beta 2.45e-03\n",
      "\n",
      "Train (14 28%) elbo: -0.6955 r_loss: -0.4320 kl: 99.3267 aux_loss: 0.0000 beta 2.65e-03\n",
      "Valid (14 28%) elbo: -0.7457 r_loss: -0.4700 kl: 103.9100 aux_loss: 0.0000 beta 2.65e-03\n",
      "\n",
      "Train (15 30%) elbo: -0.7105 r_loss: -0.4381 kl: 95.3219 aux_loss: 0.0000 beta 2.86e-03\n",
      "Valid (15 30%) elbo: -0.6787 r_loss: -0.4188 kl: 90.9716 aux_loss: 0.0000 beta 2.86e-03\n",
      "\n",
      "Train (16 32%) elbo: -0.7199 r_loss: -0.4437 kl: 90.2283 aux_loss: 0.0000 beta 3.06e-03\n",
      "Valid (16 32%) elbo: -0.6945 r_loss: -0.4149 kl: 91.3432 aux_loss: 0.0000 beta 3.06e-03\n",
      "\n",
      "Train (17 34%) elbo: -0.7373 r_loss: -0.4555 kl: 86.2883 aux_loss: 0.0000 beta 3.27e-03\n",
      "Valid (17 34%) elbo: -0.7158 r_loss: -0.4441 kl: 83.2068 aux_loss: 0.0000 beta 3.27e-03\n",
      "\n",
      "Train (18 36%) elbo: -0.7455 r_loss: -0.4582 kl: 82.8012 aux_loss: 0.0000 beta 3.47e-03\n",
      "Valid (18 36%) elbo: -0.7393 r_loss: -0.4525 kl: 82.6588 aux_loss: 0.0000 beta 3.47e-03\n",
      "\n",
      "Train (19 38%) elbo: -0.7562 r_loss: -0.4671 kl: 78.7157 aux_loss: 0.0000 beta 3.67e-03\n",
      "Valid (19 38%) elbo: -0.7371 r_loss: -0.4643 kl: 74.2703 aux_loss: 0.0000 beta 3.67e-03\n",
      "\n",
      "Train (20 40%) elbo: -0.7710 r_loss: -0.4752 kl: 76.2808 aux_loss: 0.0000 beta 3.88e-03\n",
      "Valid (20 40%) elbo: -0.7987 r_loss: -0.4914 kl: 79.2696 aux_loss: 0.0000 beta 3.88e-03\n",
      "\n",
      "Train (21 42%) elbo: -0.7771 r_loss: -0.4781 kl: 73.2507 aux_loss: 0.0000 beta 4.08e-03\n",
      "Valid (21 42%) elbo: -0.8145 r_loss: -0.5146 kl: 73.4747 aux_loss: 0.0000 beta 4.08e-03\n",
      "\n",
      "Train (22 44%) elbo: -0.7825 r_loss: -0.4828 kl: 69.9327 aux_loss: 0.0000 beta 4.29e-03\n",
      "Valid (22 44%) elbo: -0.7741 r_loss: -0.4777 kl: 69.1482 aux_loss: 0.0000 beta 4.29e-03\n",
      "\n",
      "Train (23 46%) elbo: -0.7934 r_loss: -0.4873 kl: 68.1905 aux_loss: 0.0000 beta 4.49e-03\n",
      "Valid (23 46%) elbo: -0.8399 r_loss: -0.5317 kl: 68.6580 aux_loss: 0.0000 beta 4.49e-03\n",
      "\n",
      "Train (24 48%) elbo: -0.8028 r_loss: -0.4930 kl: 66.0012 aux_loss: 0.0000 beta 4.69e-03\n",
      "Valid (24 48%) elbo: -0.8180 r_loss: -0.5080 kl: 66.0391 aux_loss: 0.0000 beta 4.69e-03\n",
      "\n",
      "Train (25 50%) elbo: -0.8084 r_loss: -0.4949 kl: 64.0068 aux_loss: 0.0000 beta 4.90e-03\n",
      "Valid (25 50%) elbo: -0.7775 r_loss: -0.4674 kl: 63.3179 aux_loss: 0.0000 beta 4.90e-03\n",
      "\n",
      "Train (26 52%) elbo: -0.8196 r_loss: -0.5028 kl: 62.0847 aux_loss: 0.0000 beta 5.10e-03\n",
      "Epoch    25: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Valid (26 52%) elbo: -0.8264 r_loss: -0.5077 kl: 62.4700 aux_loss: 0.0000 beta 5.10e-03\n",
      "\n",
      "Train (27 54%) elbo: -0.8112 r_loss: -0.4929 kl: 59.9958 aux_loss: 0.0000 beta 5.31e-03\n",
      "Valid (27 54%) elbo: -0.8419 r_loss: -0.5276 kl: 59.2460 aux_loss: 0.0000 beta 5.31e-03\n",
      "\n",
      "Train (28 56%) elbo: -0.8239 r_loss: -0.5012 kl: 58.5717 aux_loss: 0.0000 beta 5.51e-03\n",
      "Valid (28 56%) elbo: -0.9447 r_loss: -0.6123 kl: 60.3219 aux_loss: 0.0000 beta 5.51e-03\n",
      "\n",
      "Train (29 57%) elbo: -0.8371 r_loss: -0.5082 kl: 57.5678 aux_loss: 0.0000 beta 5.71e-03\n",
      "Valid (29 57%) elbo: -0.8284 r_loss: -0.4998 kl: 57.5036 aux_loss: 0.0000 beta 5.71e-03\n",
      "\n",
      "Train (30 60%) elbo: -0.8412 r_loss: -0.5099 kl: 55.9767 aux_loss: 0.0000 beta 5.92e-03\n",
      "Valid (30 60%) elbo: -0.8726 r_loss: -0.5335 kl: 57.2873 aux_loss: 0.0000 beta 5.92e-03\n",
      "\n",
      "Train (31 62%) elbo: -0.8457 r_loss: -0.5114 kl: 54.5993 aux_loss: 0.0000 beta 6.12e-03\n",
      "Valid (31 62%) elbo: -0.8240 r_loss: -0.5077 kl: 51.6668 aux_loss: 0.0000 beta 6.12e-03\n",
      "\n",
      "Train (32 64%) elbo: -0.8632 r_loss: -0.5249 kl: 53.4760 aux_loss: 0.0000 beta 6.33e-03\n",
      "Valid (32 64%) elbo: -0.8703 r_loss: -0.5293 kl: 53.8991 aux_loss: 0.0000 beta 6.33e-03\n",
      "\n",
      "Train (33 66%) elbo: -0.8594 r_loss: -0.5196 kl: 52.0329 aux_loss: 0.0000 beta 6.53e-03\n",
      "Valid (33 66%) elbo: -0.7866 r_loss: -0.4502 kl: 51.5058 aux_loss: 0.0000 beta 6.53e-03\n",
      "\n",
      "Train (34 68%) elbo: -0.8677 r_loss: -0.5247 kl: 50.9324 aux_loss: 0.0000 beta 6.73e-03\n",
      "Valid (34 68%) elbo: -0.8663 r_loss: -0.5151 kl: 52.1533 aux_loss: 0.0000 beta 6.73e-03\n",
      "\n",
      "Train (35 70%) elbo: -0.8777 r_loss: -0.5298 kl: 50.1314 aux_loss: 0.0000 beta 6.94e-03\n",
      "Valid (35 70%) elbo: -0.9102 r_loss: -0.5681 kl: 49.3063 aux_loss: 0.0000 beta 6.94e-03\n",
      "\n",
      "Train (36 72%) elbo: -0.8823 r_loss: -0.5308 kl: 49.1972 aux_loss: 0.0000 beta 7.14e-03\n",
      "Valid (36 72%) elbo: -0.8937 r_loss: -0.5427 kl: 49.1324 aux_loss: 0.0000 beta 7.14e-03\n",
      "\n",
      "Train (37 74%) elbo: -0.8935 r_loss: -0.5416 kl: 47.8943 aux_loss: 0.0000 beta 7.35e-03\n",
      "Valid (37 74%) elbo: -0.8589 r_loss: -0.5282 kl: 45.0179 aux_loss: 0.0000 beta 7.35e-03\n",
      "\n",
      "Train (38 76%) elbo: -0.8911 r_loss: -0.5380 kl: 46.7688 aux_loss: 0.0000 beta 7.55e-03\n",
      "Valid (38 76%) elbo: -0.8882 r_loss: -0.5420 kl: 45.8509 aux_loss: 0.0000 beta 7.55e-03\n",
      "\n",
      "Train (39 78%) elbo: -0.8978 r_loss: -0.5401 kl: 46.1263 aux_loss: 0.0000 beta 7.76e-03\n",
      "Valid (39 78%) elbo: -0.9194 r_loss: -0.5690 kl: 45.1858 aux_loss: 0.0000 beta 7.76e-03\n",
      "\n",
      "Train (40 80%) elbo: -0.9050 r_loss: -0.5482 kl: 44.8299 aux_loss: 0.0000 beta 7.96e-03\n",
      "Epoch    39: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Valid (40 80%) elbo: -0.8898 r_loss: -0.5458 kl: 43.2262 aux_loss: 0.0000 beta 7.96e-03\n",
      "\n",
      "Train (41 82%) elbo: -0.9064 r_loss: -0.5478 kl: 43.9199 aux_loss: 0.0000 beta 8.16e-03\n",
      "Valid (41 82%) elbo: -0.8779 r_loss: -0.5228 kl: 43.4945 aux_loss: 0.0000 beta 8.16e-03\n",
      "\n",
      "Train (42 84%) elbo: -0.9174 r_loss: -0.5539 kl: 43.4487 aux_loss: 0.0000 beta 8.37e-03\n",
      "Valid (42 84%) elbo: -0.9207 r_loss: -0.5499 kl: 44.3195 aux_loss: 0.0000 beta 8.37e-03\n",
      "\n",
      "Train (43 86%) elbo: -0.9207 r_loss: -0.5538 kl: 42.8122 aux_loss: 0.0000 beta 8.57e-03\n",
      "Valid (43 86%) elbo: -0.8918 r_loss: -0.5299 kl: 42.2182 aux_loss: 0.0000 beta 8.57e-03\n",
      "\n",
      "Train (44 88%) elbo: -0.9278 r_loss: -0.5619 kl: 41.6926 aux_loss: 0.0000 beta 8.78e-03\n",
      "Valid (44 88%) elbo: -0.7859 r_loss: -0.4394 kl: 39.4816 aux_loss: 0.0000 beta 8.78e-03\n",
      "\n",
      "Train (45 90%) elbo: -0.9426 r_loss: -0.5678 kl: 41.7320 aux_loss: 0.0000 beta 8.98e-03\n",
      "Valid (45 90%) elbo: -0.9777 r_loss: -0.5927 kl: 42.8751 aux_loss: 0.0000 beta 8.98e-03\n",
      "\n",
      "Train (46 92%) elbo: -0.9436 r_loss: -0.5703 kl: 40.6477 aux_loss: 0.0000 beta 9.18e-03\n",
      "Valid (46 92%) elbo: -0.8673 r_loss: -0.5186 kl: 37.9687 aux_loss: 0.0000 beta 9.18e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train (47 94%) elbo: -0.9479 r_loss: -0.5707 kl: 40.1848 aux_loss: 0.0000 beta 9.39e-03\n",
      "Valid (47 94%) elbo: -0.9669 r_loss: -0.5881 kl: 40.3479 aux_loss: 0.0000 beta 9.39e-03\n",
      "\n",
      "Train (48 96%) elbo: -0.9512 r_loss: -0.5745 kl: 39.2787 aux_loss: 0.0000 beta 9.59e-03\n",
      "Valid (48 96%) elbo: -0.9453 r_loss: -0.5673 kl: 39.4167 aux_loss: 0.0000 beta 9.59e-03\n",
      "\n",
      "Train (49 98%) elbo: -0.9621 r_loss: -0.5802 kl: 38.9880 aux_loss: 0.0000 beta 9.80e-03\n",
      "Valid (49 98%) elbo: -0.9917 r_loss: -0.5902 kl: 40.9842 aux_loss: 0.0000 beta 9.80e-03\n",
      "\n",
      "Train (50 100%) elbo: -0.9592 r_loss: -0.5766 kl: 38.2621 aux_loss: 0.0000 beta 1.00e-02\n",
      "Valid (50 100%) elbo: -1.0519 r_loss: -0.6751 kl: 37.6811 aux_loss: 0.0000 beta 1.00e-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use at least 50 iterations to get good results\n",
    "train(data_loader,valid_data_loader,model,optimizer,scheduler,loss_fn=nll_loss,kl_loss_fn=kl_loss_multi,n_iters=50,use_softmax=True,max_beta=1e-2,print_every=1,plot_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(),\"../Saved_models/ToyDataset/CNNVAE_nll_map.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
