{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train script for Ladder VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../Modules\")\n",
    "sys.path.append(\"../../Datasets\")\n",
    "\n",
    "# local imports\n",
    "from train import train\n",
    "from helpers import nll_loss\n",
    "from models import LadderVAE\n",
    "from ToyDatasets.timeSeries import Sinusoids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_steps = 16\n",
    "dataset_size = 5000\n",
    "num_classes = 10\n",
    "\n",
    "data_loader = DataLoader(Sinusoids(num_steps,virtual_size=dataset_size,quantization=num_classes),batch_size=batch_size,shuffle=True)\n",
    "valid_data_loader = DataLoader(Sinusoids(num_steps,virtual_size=dataset_size,quantization=num_classes),batch_size=batch_size,shuffle=True)\n",
    "\n",
    "batch_loader = iter(data_loader)\n",
    "valid_batch_loader = iter(valid_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters 870026\n",
      "Forward pass succesfull\n"
     ]
    }
   ],
   "source": [
    "model = LadderVAE(input_size=1,hidden_sizes=[350,250,150],latent_sizes=[100,40,20],recon_hidden_size=256,output_size=num_classes,use_softmax=True)\n",
    "print(\"Number of trainable parameters {}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "# test forward pass\n",
    "try:\n",
    "    initial_batch = batch_loader.next()\n",
    "    x = Variable(initial_batch).type(torch.FloatTensor).transpose(1,0)\n",
    "    test,_ = model(x)\n",
    "    assert (test.shape[0] == x.shape[0] and test.shape[1] == x.shape[1] and test.shape[2] == num_classes)\n",
    "    print(\"Forward pass succesfull\")\n",
    "except:\n",
    "    print(\"Error in forward pass. Output should have shape: {} but had {}\".format(x.contiguous().view(-1).shape,test.view(-1).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate,weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"min\",factor=0.5,verbose=True,cooldown=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train (1 2%) elbo: -1.6605 r_loss: -1.6605 kl: 939.3771 aux_loss: 0.0000 beta 0.00e+00\n",
      "Valid (1 2%) elbo: -1.1942 r_loss: -1.1942 kl: 1862.4470 aux_loss: 0.0000 beta 0.00e+00\n",
      "\n",
      "Train (2 4%) elbo: -1.0346 r_loss: -0.9094 kl: 613.6066 aux_loss: 0.0000 beta 2.04e-04\n",
      "Valid (2 4%) elbo: -0.8128 r_loss: -0.7327 kl: 392.2246 aux_loss: 0.0000 beta 2.04e-04\n",
      "\n",
      "Train (3 6%) elbo: -0.7733 r_loss: -0.6456 kl: 312.8633 aux_loss: 0.0000 beta 4.08e-04\n",
      "Valid (3 6%) elbo: -0.6707 r_loss: -0.5519 kl: 290.9831 aux_loss: 0.0000 beta 4.08e-04\n",
      "\n",
      "Train (4 8%) elbo: -0.6757 r_loss: -0.5221 kl: 250.9794 aux_loss: 0.0000 beta 6.12e-04\n",
      "Valid (4 8%) elbo: -0.5217 r_loss: -0.3869 kl: 220.2866 aux_loss: 0.0000 beta 6.12e-04\n",
      "\n",
      "Train (5 10%) elbo: -0.6132 r_loss: -0.4386 kl: 213.8837 aux_loss: 0.0000 beta 8.16e-04\n",
      "Valid (5 10%) elbo: -0.4447 r_loss: -0.2955 kl: 182.8190 aux_loss: 0.0000 beta 8.16e-04\n",
      "\n",
      "Train (6 12%) elbo: -0.5412 r_loss: -0.3458 kl: 191.4766 aux_loss: 0.0000 beta 1.02e-03\n",
      "Valid (6 12%) elbo: -0.4169 r_loss: -0.2255 kl: 187.6506 aux_loss: 0.0000 beta 1.02e-03\n",
      "\n",
      "Train (7 14%) elbo: -0.5510 r_loss: -0.3267 kl: 183.2146 aux_loss: 0.0000 beta 1.22e-03\n",
      "Valid (7 14%) elbo: -0.4241 r_loss: -0.1986 kl: 184.1305 aux_loss: 0.0000 beta 1.22e-03\n",
      "\n",
      "Train (8 16%) elbo: -0.5221 r_loss: -0.2788 kl: 170.3082 aux_loss: 0.0000 beta 1.43e-03\n",
      "Valid (8 16%) elbo: -0.4276 r_loss: -0.1829 kl: 171.3472 aux_loss: 0.0000 beta 1.43e-03\n",
      "\n",
      "Train (9 18%) elbo: -0.5080 r_loss: -0.2496 kl: 158.2851 aux_loss: 0.0000 beta 1.63e-03\n",
      "Valid (9 18%) elbo: -0.4197 r_loss: -0.1693 kl: 153.3900 aux_loss: 0.0000 beta 1.63e-03\n",
      "\n",
      "Train (10 20%) elbo: -0.4942 r_loss: -0.2199 kl: 149.3437 aux_loss: 0.0000 beta 1.84e-03\n",
      "Valid (10 20%) elbo: -0.3771 r_loss: -0.1273 kl: 135.9810 aux_loss: 0.0000 beta 1.84e-03\n",
      "\n",
      "Train (11 22%) elbo: -0.4926 r_loss: -0.2099 kl: 138.4919 aux_loss: 0.0000 beta 2.04e-03\n",
      "Valid (11 22%) elbo: -0.4260 r_loss: -0.1424 kl: 138.9380 aux_loss: 0.0000 beta 2.04e-03\n",
      "\n",
      "Train (12 24%) elbo: -0.4767 r_loss: -0.1848 kl: 130.0357 aux_loss: 0.0000 beta 2.24e-03\n",
      "Valid (12 24%) elbo: -0.3977 r_loss: -0.1243 kl: 121.7812 aux_loss: 0.0000 beta 2.24e-03\n",
      "\n",
      "Train (13 26%) elbo: -0.4824 r_loss: -0.1838 kl: 121.9299 aux_loss: 0.0000 beta 2.45e-03\n",
      "Valid (13 26%) elbo: -0.3677 r_loss: -0.0813 kl: 116.9460 aux_loss: 0.0000 beta 2.45e-03\n",
      "\n",
      "Train (14 28%) elbo: -0.4850 r_loss: -0.1785 kl: 115.5044 aux_loss: 0.0000 beta 2.65e-03\n",
      "Valid (14 28%) elbo: -0.4098 r_loss: -0.1132 kl: 111.7856 aux_loss: 0.0000 beta 2.65e-03\n",
      "\n",
      "Train (15 30%) elbo: -0.4664 r_loss: -0.1561 kl: 108.6155 aux_loss: 0.0000 beta 2.86e-03\n",
      "Valid (15 30%) elbo: -0.3601 r_loss: -0.0698 kl: 101.6353 aux_loss: 0.0000 beta 2.86e-03\n",
      "\n",
      "Train (16 32%) elbo: -0.4794 r_loss: -0.1669 kl: 102.0754 aux_loss: 0.0000 beta 3.06e-03\n",
      "Valid (16 32%) elbo: -0.4921 r_loss: -0.1604 kl: 108.3254 aux_loss: 0.0000 beta 3.06e-03\n",
      "\n",
      "Train (17 34%) elbo: -0.4484 r_loss: -0.1429 kl: 93.5814 aux_loss: 0.0000 beta 3.27e-03\n",
      "Valid (17 34%) elbo: -0.3559 r_loss: -0.0810 kl: 84.1681 aux_loss: 0.0000 beta 3.27e-03\n",
      "\n",
      "Train (18 36%) elbo: -0.4474 r_loss: -0.1431 kl: 87.7196 aux_loss: 0.0000 beta 3.47e-03\n",
      "Valid (18 36%) elbo: -0.3590 r_loss: -0.0845 kl: 79.1170 aux_loss: 0.0000 beta 3.47e-03\n",
      "\n",
      "Train (19 38%) elbo: -0.4165 r_loss: -0.1178 kl: 81.3032 aux_loss: 0.0000 beta 3.67e-03\n",
      "Valid (19 38%) elbo: -0.4378 r_loss: -0.1395 kl: 81.1924 aux_loss: 0.0000 beta 3.67e-03\n",
      "\n",
      "Train (20 40%) elbo: -0.4156 r_loss: -0.1134 kl: 77.9328 aux_loss: 0.0000 beta 3.88e-03\n",
      "Valid (20 40%) elbo: -0.3584 r_loss: -0.0753 kl: 72.9984 aux_loss: 0.0000 beta 3.88e-03\n",
      "\n",
      "Train (21 42%) elbo: -0.4149 r_loss: -0.1115 kl: 74.3297 aux_loss: 0.0000 beta 4.08e-03\n",
      "Valid (21 42%) elbo: -0.3262 r_loss: -0.0517 kl: 67.2591 aux_loss: 0.0000 beta 4.08e-03\n",
      "\n",
      "Train (22 44%) elbo: -0.4115 r_loss: -0.1072 kl: 71.0013 aux_loss: 0.0000 beta 4.29e-03\n",
      "Valid (22 44%) elbo: -0.3547 r_loss: -0.0585 kl: 69.1058 aux_loss: 0.0000 beta 4.29e-03\n",
      "\n",
      "Train (23 46%) elbo: -0.4189 r_loss: -0.1096 kl: 68.8916 aux_loss: 0.0000 beta 4.49e-03\n",
      "Valid (23 46%) elbo: -0.4472 r_loss: -0.1531 kl: 65.5102 aux_loss: 0.0000 beta 4.49e-03\n",
      "\n",
      "Train (24 48%) elbo: -0.4223 r_loss: -0.1091 kl: 66.7285 aux_loss: 0.0000 beta 4.69e-03\n",
      "Valid (24 48%) elbo: -0.4202 r_loss: -0.1101 kl: 66.0492 aux_loss: 0.0000 beta 4.69e-03\n",
      "\n",
      "Train (25 50%) elbo: -0.4145 r_loss: -0.0976 kl: 64.7030 aux_loss: 0.0000 beta 4.90e-03\n",
      "Valid (25 50%) elbo: -0.3807 r_loss: -0.0808 kl: 61.2233 aux_loss: 0.0000 beta 4.90e-03\n",
      "\n",
      "Train (26 52%) elbo: -0.4249 r_loss: -0.1012 kl: 63.4479 aux_loss: 0.0000 beta 5.10e-03\n",
      "Valid (26 52%) elbo: -0.3962 r_loss: -0.0824 kl: 61.4899 aux_loss: 0.0000 beta 5.10e-03\n",
      "\n",
      "Train (27 54%) elbo: -0.4345 r_loss: -0.0991 kl: 63.2041 aux_loss: 0.0000 beta 5.31e-03\n",
      "Valid (27 54%) elbo: -0.4130 r_loss: -0.1073 kl: 57.6156 aux_loss: 0.0000 beta 5.31e-03\n",
      "\n",
      "Train (28 56%) elbo: -0.4505 r_loss: -0.1079 kl: 62.1916 aux_loss: 0.0000 beta 5.51e-03\n",
      "Valid (28 56%) elbo: -0.3972 r_loss: -0.0682 kl: 59.7033 aux_loss: 0.0000 beta 5.51e-03\n",
      "\n",
      "Train (29 57%) elbo: -0.4387 r_loss: -0.0915 kl: 60.7484 aux_loss: 0.0000 beta 5.71e-03\n",
      "Valid (29 57%) elbo: -0.3872 r_loss: -0.0405 kl: 60.6827 aux_loss: 0.0000 beta 5.71e-03\n",
      "\n",
      "Train (30 60%) elbo: -0.4587 r_loss: -0.1002 kl: 60.5690 aux_loss: 0.0000 beta 5.92e-03\n",
      "Valid (30 60%) elbo: -0.4257 r_loss: -0.0432 kl: 64.6443 aux_loss: 0.0000 beta 5.92e-03\n",
      "\n",
      "Train (31 62%) elbo: -0.4704 r_loss: -0.1034 kl: 59.9335 aux_loss: 0.0000 beta 6.12e-03\n",
      "Valid (31 62%) elbo: -0.4179 r_loss: -0.0683 kl: 57.0918 aux_loss: 0.0000 beta 6.12e-03\n",
      "\n",
      "Train (32 64%) elbo: -0.4702 r_loss: -0.0991 kl: 58.6477 aux_loss: 0.0000 beta 6.33e-03\n",
      "Epoch    31: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Valid (32 64%) elbo: -0.4508 r_loss: -0.1036 kl: 54.8841 aux_loss: 0.0000 beta 6.33e-03\n",
      "\n",
      "Train (33 66%) elbo: -0.4666 r_loss: -0.0928 kl: 57.2399 aux_loss: 0.0000 beta 6.53e-03\n",
      "Valid (33 66%) elbo: -0.4337 r_loss: -0.0636 kl: 56.6641 aux_loss: 0.0000 beta 6.53e-03\n",
      "\n",
      "Train (34 68%) elbo: -0.4693 r_loss: -0.0911 kl: 56.1534 aux_loss: 0.0000 beta 6.73e-03\n",
      "Valid (34 68%) elbo: -0.4356 r_loss: -0.0703 kl: 54.2368 aux_loss: 0.0000 beta 6.73e-03\n",
      "\n",
      "Train (35 70%) elbo: -0.4944 r_loss: -0.1046 kl: 56.1897 aux_loss: 0.0000 beta 6.94e-03\n",
      "Valid (35 70%) elbo: -0.4286 r_loss: -0.0581 kl: 53.3956 aux_loss: 0.0000 beta 6.94e-03\n",
      "\n",
      "Train (36 72%) elbo: -0.4844 r_loss: -0.0902 kl: 55.1847 aux_loss: 0.0000 beta 7.14e-03\n",
      "Valid (36 72%) elbo: -0.4931 r_loss: -0.1243 kl: 51.6446 aux_loss: 0.0000 beta 7.14e-03\n",
      "\n",
      "Train (37 74%) elbo: -0.4997 r_loss: -0.0965 kl: 54.8888 aux_loss: 0.0000 beta 7.35e-03\n",
      "Valid (37 74%) elbo: -0.4289 r_loss: -0.0608 kl: 50.0965 aux_loss: 0.0000 beta 7.35e-03\n",
      "\n",
      "Train (38 76%) elbo: -0.5183 r_loss: -0.1068 kl: 54.4913 aux_loss: 0.0000 beta 7.55e-03\n",
      "Valid (38 76%) elbo: -0.4565 r_loss: -0.0775 kl: 50.1832 aux_loss: 0.0000 beta 7.55e-03\n",
      "\n",
      "Train (39 78%) elbo: -0.5160 r_loss: -0.0995 kl: 53.6971 aux_loss: 0.0000 beta 7.76e-03\n",
      "Valid (39 78%) elbo: -0.4828 r_loss: -0.0841 kl: 51.4132 aux_loss: 0.0000 beta 7.76e-03\n",
      "\n",
      "Train (40 80%) elbo: -0.5347 r_loss: -0.1121 kl: 53.0984 aux_loss: 0.0000 beta 7.96e-03\n",
      "Valid (40 80%) elbo: -0.4972 r_loss: -0.1193 kl: 47.4805 aux_loss: 0.0000 beta 7.96e-03\n",
      "\n",
      "Train (41 82%) elbo: -0.5352 r_loss: -0.1058 kl: 52.6025 aux_loss: 0.0000 beta 8.16e-03\n",
      "Valid (41 82%) elbo: -0.5105 r_loss: -0.0822 kl: 52.4662 aux_loss: 0.0000 beta 8.16e-03\n",
      "\n",
      "Train (42 84%) elbo: -0.5507 r_loss: -0.1107 kl: 52.5854 aux_loss: 0.0000 beta 8.37e-03\n",
      "Valid (42 84%) elbo: -0.5216 r_loss: -0.1093 kl: 49.2732 aux_loss: 0.0000 beta 8.37e-03\n",
      "\n",
      "Train (43 86%) elbo: -0.5564 r_loss: -0.1104 kl: 52.0285 aux_loss: 0.0000 beta 8.57e-03\n",
      "Valid (43 86%) elbo: -0.4992 r_loss: -0.0763 kl: 49.3400 aux_loss: 0.0000 beta 8.57e-03\n",
      "\n",
      "Train (44 88%) elbo: -0.5535 r_loss: -0.1027 kl: 51.3757 aux_loss: 0.0000 beta 8.78e-03\n",
      "Valid (44 88%) elbo: -0.5390 r_loss: -0.1253 kl: 47.1476 aux_loss: 0.0000 beta 8.78e-03\n",
      "\n",
      "Train (45 90%) elbo: -0.5690 r_loss: -0.1094 kl: 51.1908 aux_loss: 0.0000 beta 8.98e-03\n",
      "Valid (45 90%) elbo: -0.5076 r_loss: -0.0805 kl: 47.5610 aux_loss: 0.0000 beta 8.98e-03\n",
      "\n",
      "Train (46 92%) elbo: -0.5779 r_loss: -0.1128 kl: 50.6389 aux_loss: 0.0000 beta 9.18e-03\n",
      "Valid (46 92%) elbo: -0.5575 r_loss: -0.1002 kl: 49.7952 aux_loss: 0.0000 beta 9.18e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train (47 94%) elbo: -0.5851 r_loss: -0.1143 kl: 50.1538 aux_loss: 0.0000 beta 9.39e-03\n",
      "Valid (47 94%) elbo: -0.5152 r_loss: -0.0758 kl: 46.8070 aux_loss: 0.0000 beta 9.39e-03\n",
      "\n",
      "Train (48 96%) elbo: -0.5975 r_loss: -0.1184 kl: 49.9533 aux_loss: 0.0000 beta 9.59e-03\n",
      "Valid (48 96%) elbo: -0.5365 r_loss: -0.1058 kl: 44.9010 aux_loss: 0.0000 beta 9.59e-03\n",
      "\n",
      "Train (49 98%) elbo: -0.6115 r_loss: -0.1249 kl: 49.6695 aux_loss: 0.0000 beta 9.80e-03\n",
      "Valid (49 98%) elbo: -0.5604 r_loss: -0.1016 kl: 46.8392 aux_loss: 0.0000 beta 9.80e-03\n",
      "\n",
      "Train (50 100%) elbo: -0.6236 r_loss: -0.1296 kl: 49.4020 aux_loss: 0.0000 beta 1.00e-02\n",
      "Valid (50 100%) elbo: -0.5886 r_loss: -0.1240 kl: 46.4611 aux_loss: 0.0000 beta 1.00e-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use at least 50 iterations to get good results\n",
    "train(data_loader,valid_data_loader,model,optimizer,scheduler,loss_fn=nll_loss,kl_loss_fn=None,n_iters=50,use_softmax=True,max_beta=1e-2,print_every=1,plot_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(),\"../../Saved_models/ToyDataset/LadderVAE_nll_best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model results:\n",
    "\n",
    "### Model 1\n",
    "with the following settings: \n",
    "\n",
    "hidden_sizes=[256,128,64], latent_sizes=[32,16,8], recon_hidden_size=128, with 279940 trainable parameters\n",
    "\n",
    "| Dataset | ELBO | nll | kl | beta |\n",
    "|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|\n",
    "| Train | -0.4809 | -0.1179 | 36.2942 | 1e-2 |\n",
    "| Valid | -0.4773| -0.1227 | 35.4518 | 1e-2 |\n",
    "\n",
    "### Model 2\n",
    "with the following settings: \n",
    "\n",
    "hidden_sizes=[256,128,64], latent_sizes=[64,32,16], recon_hidden_size=128, with 357044 trainable parameters\n",
    "\n",
    "| Dataset | ELBO | nll | kl | beta |\n",
    "|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|\n",
    "| Train | -0.4754 | -0.0587 | 41.6707 | 1e-2 |\n",
    "| Valid | -0.4530| -0.0471 | 40.5872 | 1e-2 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
