{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train script for CNN VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../Modules\")\n",
    "sys.path.append(\"../../Datasets\")\n",
    "\n",
    "# local imports\n",
    "from train import train\n",
    "from helpers import kl_loss,nll_loss,mse_loss,kl_loss_multi\n",
    "from models import CNNVAESmall\n",
    "from ToyDatasets.timeSeries import Sinusoids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_steps = 16\n",
    "dataset_size = 5000\n",
    "num_classes = 10\n",
    "\n",
    "data_loader = DataLoader(Sinusoids(num_steps,virtual_size=dataset_size,quantization=num_classes),batch_size=batch_size,shuffle=True)\n",
    "valid_data_loader = DataLoader(Sinusoids(num_steps,virtual_size=dataset_size,quantization=num_classes),batch_size=batch_size,shuffle=True)\n",
    "\n",
    "batch_loader = iter(data_loader)\n",
    "valid_batch_loader = iter(valid_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters 860778\n",
      "Forward pass succesfull\n"
     ]
    }
   ],
   "source": [
    "model = CNNVAESmall(input_size=1,conv_size=160,latent_size=64,output_size=num_classes,use_softmax=True)\n",
    "print(\"Number of trainable parameters {}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "# test forward pass\n",
    "try:\n",
    "    initial_batch = batch_loader.next()\n",
    "    x = Variable(initial_batch).type(torch.FloatTensor).transpose(1,0)\n",
    "    test,_ = model(x)\n",
    "    assert (test.shape[0] == x.shape[0] and test.shape[1] == x.shape[1] and test.shape[2] == num_classes)\n",
    "    print(\"Forward pass succesfull\")\n",
    "except:\n",
    "    print(\"Error in forward pass. Output should have shape: {} but had {}\".format(x.contiguous().view(-1).shape,test.view(-1).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate,weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"min\",factor=0.5,verbose=True,cooldown=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train (1 2%) elbo: -2.1801 r_loss: -2.1801 kl: 19.1251 aux_loss: 0.0000 beta 0.00e+00\n",
      "Valid (1 2%) elbo: -2.0258 r_loss: -2.0258 kl: 66.1176 aux_loss: 0.0000 beta 0.00e+00\n",
      "\n",
      "Train (2 4%) elbo: -1.8122 r_loss: -1.8047 kl: 36.7477 aux_loss: 0.0000 beta 2.04e-04\n",
      "Valid (2 4%) elbo: -1.5533 r_loss: -1.5368 kl: 80.7465 aux_loss: 0.0000 beta 2.04e-04\n",
      "\n",
      "Train (3 6%) elbo: -1.3512 r_loss: -1.3237 kl: 67.3784 aux_loss: 0.0000 beta 4.08e-04\n",
      "Valid (3 6%) elbo: -1.3235 r_loss: -1.2904 kl: 81.2450 aux_loss: 0.0000 beta 4.08e-04\n",
      "\n",
      "Train (4 8%) elbo: -1.2319 r_loss: -1.1877 kl: 72.1298 aux_loss: 0.0000 beta 6.12e-04\n",
      "Valid (4 8%) elbo: -1.2240 r_loss: -1.1851 kl: 63.4491 aux_loss: 0.0000 beta 6.12e-04\n",
      "\n",
      "Train (5 10%) elbo: -1.1987 r_loss: -1.1414 kl: 70.1691 aux_loss: 0.0000 beta 8.16e-04\n",
      "Valid (5 10%) elbo: -1.0910 r_loss: -1.0341 kl: 69.7053 aux_loss: 0.0000 beta 8.16e-04\n",
      "\n",
      "Train (6 12%) elbo: -1.1835 r_loss: -1.1182 kl: 64.0078 aux_loss: 0.0000 beta 1.02e-03\n",
      "Valid (6 12%) elbo: -1.2064 r_loss: -1.1493 kl: 55.9443 aux_loss: 0.0000 beta 1.02e-03\n",
      "\n",
      "Train (7 14%) elbo: -1.1854 r_loss: -1.1139 kl: 58.4313 aux_loss: 0.0000 beta 1.22e-03\n",
      "Valid (7 14%) elbo: -1.0152 r_loss: -0.9455 kl: 56.8864 aux_loss: 0.0000 beta 1.22e-03\n",
      "\n",
      "Train (8 16%) elbo: -1.1715 r_loss: -1.0938 kl: 54.4130 aux_loss: 0.0000 beta 1.43e-03\n",
      "Valid (8 16%) elbo: -1.1301 r_loss: -1.0555 kl: 52.2550 aux_loss: 0.0000 beta 1.43e-03\n",
      "\n",
      "Train (9 18%) elbo: -1.1630 r_loss: -1.0788 kl: 51.5563 aux_loss: 0.0000 beta 1.63e-03\n",
      "Valid (9 18%) elbo: -1.1179 r_loss: -1.0348 kl: 50.9497 aux_loss: 0.0000 beta 1.63e-03\n",
      "\n",
      "Train (10 20%) elbo: -1.1441 r_loss: -1.0545 kl: 48.7973 aux_loss: 0.0000 beta 1.84e-03\n",
      "Valid (10 20%) elbo: -1.2544 r_loss: -1.1624 kl: 50.0912 aux_loss: 0.0000 beta 1.84e-03\n",
      "\n",
      "Train (11 22%) elbo: -1.1451 r_loss: -1.0492 kl: 46.9781 aux_loss: 0.0000 beta 2.04e-03\n",
      "Valid (11 22%) elbo: -1.0616 r_loss: -0.9627 kl: 48.5039 aux_loss: 0.0000 beta 2.04e-03\n",
      "\n",
      "Train (12 24%) elbo: -1.0893 r_loss: -0.9857 kl: 46.1171 aux_loss: 0.0000 beta 2.24e-03\n",
      "Valid (12 24%) elbo: -1.1448 r_loss: -1.0453 kl: 44.3242 aux_loss: 0.0000 beta 2.24e-03\n",
      "\n",
      "Train (13 26%) elbo: -0.9810 r_loss: -0.8599 kl: 49.4516 aux_loss: 0.0000 beta 2.45e-03\n",
      "Valid (13 26%) elbo: -0.9731 r_loss: -0.8449 kl: 52.3551 aux_loss: 0.0000 beta 2.45e-03\n",
      "\n",
      "Train (14 28%) elbo: -0.9154 r_loss: -0.7781 kl: 51.7737 aux_loss: 0.0000 beta 2.65e-03\n",
      "Valid (14 28%) elbo: -0.8735 r_loss: -0.7308 kl: 53.7691 aux_loss: 0.0000 beta 2.65e-03\n",
      "\n",
      "Train (15 30%) elbo: -0.9012 r_loss: -0.7525 kl: 52.0475 aux_loss: 0.0000 beta 2.86e-03\n",
      "Valid (15 30%) elbo: -0.9439 r_loss: -0.7983 kl: 50.9672 aux_loss: 0.0000 beta 2.86e-03\n",
      "\n",
      "Train (16 32%) elbo: -0.8779 r_loss: -0.7191 kl: 51.8591 aux_loss: 0.0000 beta 3.06e-03\n",
      "Valid (16 32%) elbo: -0.9318 r_loss: -0.7761 kl: 50.8434 aux_loss: 0.0000 beta 3.06e-03\n",
      "\n",
      "Train (17 34%) elbo: -0.8612 r_loss: -0.6937 kl: 51.3110 aux_loss: 0.0000 beta 3.27e-03\n",
      "Valid (17 34%) elbo: -0.8502 r_loss: -0.6810 kl: 51.8275 aux_loss: 0.0000 beta 3.27e-03\n",
      "\n",
      "Train (18 36%) elbo: -0.8515 r_loss: -0.6763 kl: 50.4951 aux_loss: 0.0000 beta 3.47e-03\n",
      "Valid (18 36%) elbo: -0.7947 r_loss: -0.6157 kl: 51.5720 aux_loss: 0.0000 beta 3.47e-03\n",
      "\n",
      "Train (19 38%) elbo: -0.8472 r_loss: -0.6644 kl: 49.7684 aux_loss: 0.0000 beta 3.67e-03\n",
      "Valid (19 38%) elbo: -0.8179 r_loss: -0.6318 kl: 50.6637 aux_loss: 0.0000 beta 3.67e-03\n",
      "\n",
      "Train (20 40%) elbo: -0.8530 r_loss: -0.6625 kl: 49.1139 aux_loss: 0.0000 beta 3.88e-03\n",
      "Valid (20 40%) elbo: -0.7796 r_loss: -0.5986 kl: 46.6856 aux_loss: 0.0000 beta 3.88e-03\n",
      "\n",
      "Train (21 42%) elbo: -0.8447 r_loss: -0.6516 kl: 47.2962 aux_loss: 0.0000 beta 4.08e-03\n",
      "Valid (21 42%) elbo: -0.9363 r_loss: -0.7486 kl: 45.9651 aux_loss: 0.0000 beta 4.08e-03\n",
      "\n",
      "Train (22 44%) elbo: -0.8465 r_loss: -0.6484 kl: 46.2195 aux_loss: 0.0000 beta 4.29e-03\n",
      "Valid (22 44%) elbo: -0.7849 r_loss: -0.5869 kl: 46.2038 aux_loss: 0.0000 beta 4.29e-03\n",
      "\n",
      "Train (23 46%) elbo: -0.8425 r_loss: -0.6382 kl: 45.4984 aux_loss: 0.0000 beta 4.49e-03\n",
      "Valid (23 46%) elbo: -0.8311 r_loss: -0.6249 kl: 45.9180 aux_loss: 0.0000 beta 4.49e-03\n",
      "\n",
      "Train (24 48%) elbo: -0.8407 r_loss: -0.6299 kl: 44.9045 aux_loss: 0.0000 beta 4.69e-03\n",
      "Valid (24 48%) elbo: -0.8689 r_loss: -0.6368 kl: 49.4426 aux_loss: 0.0000 beta 4.69e-03\n",
      "\n",
      "Train (25 50%) elbo: -0.8498 r_loss: -0.6353 kl: 43.7938 aux_loss: 0.0000 beta 4.90e-03\n",
      "Valid (25 50%) elbo: -0.8496 r_loss: -0.6349 kl: 43.8187 aux_loss: 0.0000 beta 4.90e-03\n",
      "\n",
      "Train (26 52%) elbo: -0.8500 r_loss: -0.6313 kl: 42.8721 aux_loss: 0.0000 beta 5.10e-03\n",
      "Valid (26 52%) elbo: -0.8530 r_loss: -0.6263 kl: 44.4415 aux_loss: 0.0000 beta 5.10e-03\n",
      "\n",
      "Train (27 54%) elbo: -0.8513 r_loss: -0.6268 kl: 42.3265 aux_loss: 0.0000 beta 5.31e-03\n",
      "Valid (27 54%) elbo: -0.8844 r_loss: -0.6536 kl: 43.4885 aux_loss: 0.0000 beta 5.31e-03\n",
      "\n",
      "Train (28 56%) elbo: -0.8550 r_loss: -0.6247 kl: 41.7935 aux_loss: 0.0000 beta 5.51e-03\n",
      "Valid (28 56%) elbo: -0.7573 r_loss: -0.5360 kl: 40.1601 aux_loss: 0.0000 beta 5.51e-03\n",
      "\n",
      "Train (29 57%) elbo: -0.8581 r_loss: -0.6254 kl: 40.7273 aux_loss: 0.0000 beta 5.71e-03\n",
      "Valid (29 57%) elbo: -0.8108 r_loss: -0.5827 kl: 39.9118 aux_loss: 0.0000 beta 5.71e-03\n",
      "\n",
      "Train (30 60%) elbo: -0.8642 r_loss: -0.6256 kl: 40.3198 aux_loss: 0.0000 beta 5.92e-03\n",
      "Valid (30 60%) elbo: -0.8916 r_loss: -0.6586 kl: 39.3621 aux_loss: 0.0000 beta 5.92e-03\n",
      "\n",
      "Train (31 62%) elbo: -0.8630 r_loss: -0.6213 kl: 39.4767 aux_loss: 0.0000 beta 6.12e-03\n",
      "Valid (31 62%) elbo: -0.8358 r_loss: -0.5975 kl: 38.9118 aux_loss: 0.0000 beta 6.12e-03\n",
      "\n",
      "Train (32 64%) elbo: -0.8774 r_loss: -0.6342 kl: 38.4406 aux_loss: 0.0000 beta 6.33e-03\n",
      "Valid (32 64%) elbo: -0.8507 r_loss: -0.6180 kl: 36.7800 aux_loss: 0.0000 beta 6.33e-03\n",
      "\n",
      "Train (33 66%) elbo: -0.8647 r_loss: -0.6176 kl: 37.8434 aux_loss: 0.0000 beta 6.53e-03\n",
      "Valid (33 66%) elbo: -0.8863 r_loss: -0.6510 kl: 36.0290 aux_loss: 0.0000 beta 6.53e-03\n",
      "\n",
      "Train (34 68%) elbo: -0.8632 r_loss: -0.6159 kl: 36.7166 aux_loss: 0.0000 beta 6.73e-03\n",
      "Valid (34 68%) elbo: -0.9359 r_loss: -0.6848 kl: 37.2869 aux_loss: 0.0000 beta 6.73e-03\n",
      "\n",
      "Train (35 70%) elbo: -0.8745 r_loss: -0.6208 kl: 36.5595 aux_loss: 0.0000 beta 6.94e-03\n",
      "Valid (35 70%) elbo: -0.9039 r_loss: -0.6514 kl: 36.3813 aux_loss: 0.0000 beta 6.94e-03\n",
      "\n",
      "Train (36 72%) elbo: -0.8980 r_loss: -0.6386 kl: 36.3233 aux_loss: 0.0000 beta 7.14e-03\n",
      "Valid (36 72%) elbo: -0.9703 r_loss: -0.7097 kl: 36.4867 aux_loss: 0.0000 beta 7.14e-03\n",
      "\n",
      "Train (37 74%) elbo: -0.8830 r_loss: -0.6226 kl: 35.4392 aux_loss: 0.0000 beta 7.35e-03\n",
      "Valid (37 74%) elbo: -0.9090 r_loss: -0.6511 kl: 35.0999 aux_loss: 0.0000 beta 7.35e-03\n",
      "\n",
      "Train (38 76%) elbo: -0.8752 r_loss: -0.6130 kl: 34.7231 aux_loss: 0.0000 beta 7.55e-03\n",
      "Valid (38 76%) elbo: -0.9057 r_loss: -0.6512 kl: 33.7144 aux_loss: 0.0000 beta 7.55e-03\n",
      "\n",
      "Train (39 78%) elbo: -0.8959 r_loss: -0.6298 kl: 34.3115 aux_loss: 0.0000 beta 7.76e-03\n",
      "Epoch    38: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Valid (39 78%) elbo: -0.8596 r_loss: -0.5876 kl: 35.0735 aux_loss: 0.0000 beta 7.76e-03\n",
      "\n",
      "Train (40 80%) elbo: -0.8659 r_loss: -0.5961 kl: 33.9054 aux_loss: 0.0000 beta 7.96e-03\n",
      "Valid (40 80%) elbo: -0.8572 r_loss: -0.5848 kl: 34.2201 aux_loss: 0.0000 beta 7.96e-03\n",
      "\n",
      "Train (41 82%) elbo: -0.8778 r_loss: -0.6020 kl: 33.7800 aux_loss: 0.0000 beta 8.16e-03\n",
      "Valid (41 82%) elbo: -0.8119 r_loss: -0.5403 kl: 33.2698 aux_loss: 0.0000 beta 8.16e-03\n",
      "\n",
      "Train (42 84%) elbo: -0.8807 r_loss: -0.5998 kl: 33.5726 aux_loss: 0.0000 beta 8.37e-03\n",
      "Valid (42 84%) elbo: -0.9196 r_loss: -0.6328 kl: 34.2718 aux_loss: 0.0000 beta 8.37e-03\n",
      "\n",
      "Train (43 86%) elbo: -0.8896 r_loss: -0.6075 kl: 32.9220 aux_loss: 0.0000 beta 8.57e-03\n",
      "Valid (43 86%) elbo: -0.9938 r_loss: -0.7104 kl: 33.0580 aux_loss: 0.0000 beta 8.57e-03\n",
      "\n",
      "Train (44 88%) elbo: -0.8863 r_loss: -0.5996 kl: 32.6729 aux_loss: 0.0000 beta 8.78e-03\n",
      "Valid (44 88%) elbo: -0.8322 r_loss: -0.5440 kl: 32.8443 aux_loss: 0.0000 beta 8.78e-03\n",
      "\n",
      "Train (45 90%) elbo: -0.8990 r_loss: -0.6090 kl: 32.2919 aux_loss: 0.0000 beta 8.98e-03\n",
      "Valid (45 90%) elbo: -0.9749 r_loss: -0.6768 kl: 33.1978 aux_loss: 0.0000 beta 8.98e-03\n",
      "\n",
      "Train (46 92%) elbo: -0.9051 r_loss: -0.6073 kl: 32.4307 aux_loss: 0.0000 beta 9.18e-03\n",
      "Valid (46 92%) elbo: -0.9118 r_loss: -0.6187 kl: 31.9224 aux_loss: 0.0000 beta 9.18e-03\n",
      "\n",
      "Train (47 94%) elbo: -0.8972 r_loss: -0.6005 kl: 31.6094 aux_loss: 0.0000 beta 9.39e-03\n",
      "Valid (47 94%) elbo: -0.9675 r_loss: -0.6734 kl: 31.3285 aux_loss: 0.0000 beta 9.39e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train (48 96%) elbo: -0.9055 r_loss: -0.6047 kl: 31.3629 aux_loss: 0.0000 beta 9.59e-03\n",
      "Valid (48 96%) elbo: -0.9452 r_loss: -0.6473 kl: 31.0601 aux_loss: 0.0000 beta 9.59e-03\n",
      "\n",
      "Train (49 98%) elbo: -0.9326 r_loss: -0.6261 kl: 31.2893 aux_loss: 0.0000 beta 9.80e-03\n",
      "Valid (49 98%) elbo: -0.8723 r_loss: -0.5569 kl: 32.1984 aux_loss: 0.0000 beta 9.80e-03\n",
      "\n",
      "Train (50 100%) elbo: -0.9300 r_loss: -0.6218 kl: 30.8118 aux_loss: 0.0000 beta 1.00e-02\n",
      "Valid (50 100%) elbo: -0.8609 r_loss: -0.5629 kl: 29.8043 aux_loss: 0.0000 beta 1.00e-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use at least 50 iterations to get good results\n",
    "train(data_loader,valid_data_loader,model,optimizer,scheduler,loss_fn=nll_loss,kl_loss_fn=kl_loss,n_iters=50,use_softmax=True,max_beta=1e-2,print_every=1,plot_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(),\"Saved_models/CNNVAE_nll.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
