{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train script for Advanced Hybrid VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../Modules\")\n",
    "sys.path.append(\"../../Datasets\")\n",
    "\n",
    "# local imports\n",
    "from train import train\n",
    "from helpers import kl_loss,nll_loss,mse_loss,kl_loss_multi\n",
    "from models import AdvancedHybridVAE\n",
    "from ToyDatasets.timeSeries import Sinusoids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_steps = 16\n",
    "dataset_size = 5000\n",
    "num_classes = 10\n",
    "\n",
    "data_loader = DataLoader(Sinusoids(num_steps,virtual_size=dataset_size,quantization=num_classes),batch_size=batch_size,shuffle=True)\n",
    "valid_data_loader = DataLoader(Sinusoids(num_steps,virtual_size=dataset_size,quantization=num_classes),batch_size=batch_size,shuffle=True)\n",
    "\n",
    "batch_loader = iter(data_loader)\n",
    "valid_batch_loader = iter(valid_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters 1054868\n",
      "Forward pass succesfull\n"
     ]
    }
   ],
   "source": [
    "model = AdvancedHybridVAE(input_size=1,conv_size=256,rnn_size=256,latent_size=64,output_size=num_classes,use_softmax=True)\n",
    "print(\"Number of trainable parameters {}\".format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "\n",
    "# test forward pass\n",
    "try:\n",
    "    initial_batch = batch_loader.next()\n",
    "    x = Variable(initial_batch).type(torch.FloatTensor).transpose(1,0)\n",
    "    test,_,_ = model(x)\n",
    "    assert (test.shape[0] == x.shape[0] and test.shape[1] == x.shape[1] and test.shape[2] == num_classes)\n",
    "    print(\"Forward pass succesfull\")\n",
    "except:\n",
    "    print(\"Error in forward pass. Output should have shape: {} but had {}\".format(x.contiguous().view(-1).shape,test.view(-1).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate,weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode=\"min\",factor=0.5,verbose=True,cooldown=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train (1 2%) elbo: -1.9719 r_loss: -1.6268 kl: 7216.6959 aux_loss: -1.1504 beta 0.00e+00\n",
      "Valid (1 2%) elbo: -0.9834 r_loss: -0.8575 kl: 24440.7910 aux_loss: -0.4198 beta 0.00e+00\n",
      "\n",
      "Train (2 4%) elbo: -1.1920 r_loss: -0.7410 kl: 1490.8751 aux_loss: -0.4893 beta 2.04e-04\n",
      "Valid (2 4%) elbo: -0.7517 r_loss: -0.5153 kl: 585.0525 aux_loss: -0.3899 beta 2.04e-04\n",
      "\n",
      "Train (3 6%) elbo: -0.7426 r_loss: -0.4643 kl: 404.4358 aux_loss: -0.3773 beta 4.08e-04\n",
      "Valid (3 6%) elbo: -0.6883 r_loss: -0.4197 kl: 390.1301 aux_loss: -0.3647 beta 4.08e-04\n",
      "\n",
      "Train (4 8%) elbo: -0.6957 r_loss: -0.3984 kl: 307.4980 aux_loss: -0.3634 beta 6.12e-04\n",
      "Valid (4 8%) elbo: -0.6853 r_loss: -0.3848 kl: 316.7516 aux_loss: -0.3550 beta 6.12e-04\n",
      "\n",
      "Train (5 10%) elbo: -0.6967 r_loss: -0.3776 kl: 258.4395 aux_loss: -0.3602 beta 8.16e-04\n",
      "Valid (5 10%) elbo: -0.7131 r_loss: -0.3927 kl: 257.0711 aux_loss: -0.3685 beta 8.16e-04\n",
      "\n",
      "Train (6 12%) elbo: -0.7001 r_loss: -0.3633 kl: 226.1144 aux_loss: -0.3536 beta 1.02e-03\n",
      "Valid (6 12%) elbo: -0.7070 r_loss: -0.3652 kl: 235.0406 aux_loss: -0.3400 beta 1.02e-03\n",
      "\n",
      "Train (7 14%) elbo: -0.7185 r_loss: -0.3629 kl: 202.5322 aux_loss: -0.3586 beta 1.22e-03\n",
      "Valid (7 14%) elbo: -0.7526 r_loss: -0.3952 kl: 190.2875 aux_loss: -0.4149 beta 1.22e-03\n",
      "\n",
      "Train (8 16%) elbo: -0.7425 r_loss: -0.3691 kl: 183.9783 aux_loss: -0.3683 beta 1.43e-03\n",
      "Valid (8 16%) elbo: -0.7628 r_loss: -0.3948 kl: 174.7016 aux_loss: -0.3948 beta 1.43e-03\n",
      "\n",
      "Train (9 18%) elbo: -0.7507 r_loss: -0.3673 kl: 166.7877 aux_loss: -0.3703 beta 1.63e-03\n",
      "Valid (9 18%) elbo: -0.7643 r_loss: -0.3879 kl: 159.1724 aux_loss: -0.3884 beta 1.63e-03\n",
      "\n",
      "Train (10 20%) elbo: -0.7662 r_loss: -0.3704 kl: 154.4287 aux_loss: -0.3740 beta 1.84e-03\n",
      "Valid (10 20%) elbo: -0.8426 r_loss: -0.4332 kl: 154.4672 aux_loss: -0.4191 beta 1.84e-03\n",
      "\n",
      "Train (11 22%) elbo: -0.7809 r_loss: -0.3754 kl: 142.4427 aux_loss: -0.3825 beta 2.04e-03\n",
      "Valid (11 22%) elbo: -0.7632 r_loss: -0.3688 kl: 137.2590 aux_loss: -0.3810 beta 2.04e-03\n",
      "\n",
      "Train (12 24%) elbo: -0.7864 r_loss: -0.3735 kl: 132.9660 aux_loss: -0.3812 beta 2.24e-03\n",
      "Valid (12 24%) elbo: -0.8030 r_loss: -0.3823 kl: 132.8864 aux_loss: -0.4078 beta 2.24e-03\n",
      "\n",
      "Train (13 26%) elbo: -0.8086 r_loss: -0.3824 kl: 126.0593 aux_loss: -0.3918 beta 2.45e-03\n",
      "Valid (13 26%) elbo: -0.7811 r_loss: -0.3737 kl: 118.8058 aux_loss: -0.3881 beta 2.45e-03\n",
      "\n",
      "Train (14 28%) elbo: -0.8061 r_loss: -0.3783 kl: 117.0377 aux_loss: -0.3909 beta 2.65e-03\n",
      "Valid (14 28%) elbo: -0.8009 r_loss: -0.3717 kl: 118.7963 aux_loss: -0.3800 beta 2.65e-03\n",
      "\n",
      "Train (15 30%) elbo: -0.8181 r_loss: -0.3811 kl: 111.3674 aux_loss: -0.3960 beta 2.86e-03\n",
      "Epoch    14: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Valid (15 30%) elbo: -0.8143 r_loss: -0.3819 kl: 109.3317 aux_loss: -0.4000 beta 2.86e-03\n",
      "\n",
      "Train (16 32%) elbo: -0.8164 r_loss: -0.3731 kl: 106.6830 aux_loss: -0.3891 beta 3.06e-03\n",
      "Valid (16 32%) elbo: -0.9187 r_loss: -0.4489 kl: 106.2118 aux_loss: -0.4823 beta 3.06e-03\n",
      "\n",
      "Train (17 34%) elbo: -0.8259 r_loss: -0.3737 kl: 102.6084 aux_loss: -0.3907 beta 3.27e-03\n",
      "Valid (17 34%) elbo: -0.8582 r_loss: -0.4053 kl: 101.4597 aux_loss: -0.4056 beta 3.27e-03\n",
      "\n",
      "Train (18 36%) elbo: -0.8442 r_loss: -0.3808 kl: 99.0544 aux_loss: -0.3991 beta 3.47e-03\n",
      "Valid (18 36%) elbo: -0.8929 r_loss: -0.4153 kl: 99.7444 aux_loss: -0.4382 beta 3.47e-03\n",
      "\n",
      "Train (19 38%) elbo: -0.8510 r_loss: -0.3813 kl: 95.0947 aux_loss: -0.4011 beta 3.67e-03\n",
      "Valid (19 38%) elbo: -0.7752 r_loss: -0.3309 kl: 92.0533 aux_loss: -0.3536 beta 3.67e-03\n",
      "\n",
      "Train (20 40%) elbo: -0.8702 r_loss: -0.3891 kl: 92.3637 aux_loss: -0.4097 beta 3.88e-03\n",
      "Valid (20 40%) elbo: -0.8182 r_loss: -0.3525 kl: 90.6166 aux_loss: -0.3809 beta 3.88e-03\n",
      "\n",
      "Train (21 42%) elbo: -0.8796 r_loss: -0.3906 kl: 89.5096 aux_loss: -0.4124 beta 4.08e-03\n",
      "Valid (21 42%) elbo: -0.9240 r_loss: -0.4173 kl: 92.0828 aux_loss: -0.4362 beta 4.08e-03\n",
      "\n",
      "Train (22 44%) elbo: -0.8938 r_loss: -0.3963 kl: 86.7589 aux_loss: -0.4191 beta 4.29e-03\n",
      "Valid (22 44%) elbo: -0.8815 r_loss: -0.3834 kl: 86.5416 aux_loss: -0.4242 beta 4.29e-03\n",
      "\n",
      "Train (23 46%) elbo: -0.8958 r_loss: -0.3945 kl: 83.6154 aux_loss: -0.4197 beta 4.49e-03\n",
      "Valid (23 46%) elbo: -0.9362 r_loss: -0.4427 kl: 80.3929 aux_loss: -0.4416 beta 4.49e-03\n",
      "\n",
      "Train (24 48%) elbo: -0.9115 r_loss: -0.4008 kl: 81.5697 aux_loss: -0.4262 beta 4.69e-03\n",
      "Valid (24 48%) elbo: -1.0037 r_loss: -0.4755 kl: 80.7249 aux_loss: -0.4974 beta 4.69e-03\n",
      "\n",
      "Train (25 50%) elbo: -0.9100 r_loss: -0.3998 kl: 78.0879 aux_loss: -0.4257 beta 4.90e-03\n",
      "Valid (25 50%) elbo: -0.9193 r_loss: -0.4050 kl: 79.5855 aux_loss: -0.4151 beta 4.90e-03\n",
      "\n",
      "Train (26 52%) elbo: -0.9355 r_loss: -0.4114 kl: 77.0160 aux_loss: -0.4375 beta 5.10e-03\n",
      "Valid (26 52%) elbo: -0.9614 r_loss: -0.4215 kl: 78.9693 aux_loss: -0.4567 beta 5.10e-03\n",
      "\n",
      "Train (27 54%) elbo: -0.9459 r_loss: -0.4150 kl: 75.0840 aux_loss: -0.4418 beta 5.31e-03\n",
      "Valid (27 54%) elbo: -0.9929 r_loss: -0.4477 kl: 77.0600 aux_loss: -0.4543 beta 5.31e-03\n",
      "\n",
      "Train (28 56%) elbo: -0.9475 r_loss: -0.4142 kl: 72.5869 aux_loss: -0.4445 beta 5.51e-03\n",
      "Valid (28 56%) elbo: -0.8988 r_loss: -0.3779 kl: 70.3048 aux_loss: -0.4448 beta 5.51e-03\n",
      "\n",
      "Train (29 57%) elbo: -0.9640 r_loss: -0.4211 kl: 71.2663 aux_loss: -0.4523 beta 5.71e-03\n",
      "Valid (29 57%) elbo: -0.8401 r_loss: -0.3403 kl: 67.4344 aux_loss: -0.3814 beta 5.71e-03\n",
      "\n",
      "Train (30 60%) elbo: -0.9687 r_loss: -0.4199 kl: 69.7030 aux_loss: -0.4539 beta 5.92e-03\n",
      "Valid (30 60%) elbo: -0.9326 r_loss: -0.3966 kl: 68.4699 aux_loss: -0.4361 beta 5.92e-03\n",
      "\n",
      "Train (31 62%) elbo: -0.9692 r_loss: -0.4200 kl: 67.4348 aux_loss: -0.4544 beta 6.12e-03\n",
      "Epoch    30: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Valid (31 62%) elbo: -0.9667 r_loss: -0.4300 kl: 65.0326 aux_loss: -0.4620 beta 6.12e-03\n",
      "\n",
      "Train (32 64%) elbo: -0.9739 r_loss: -0.4206 kl: 65.8730 aux_loss: -0.4552 beta 6.33e-03\n",
      "Valid (32 64%) elbo: -1.0793 r_loss: -0.4925 kl: 68.9146 aux_loss: -0.5025 beta 6.33e-03\n",
      "\n",
      "Train (33 66%) elbo: -0.9821 r_loss: -0.4216 kl: 64.7401 aux_loss: -0.4592 beta 6.53e-03\n",
      "Valid (33 66%) elbo: -0.9287 r_loss: -0.4086 kl: 59.5997 aux_loss: -0.4363 beta 6.53e-03\n",
      "\n",
      "Train (34 68%) elbo: -0.9944 r_loss: -0.4288 kl: 63.1877 aux_loss: -0.4666 beta 6.73e-03\n",
      "Valid (34 68%) elbo: -0.9800 r_loss: -0.4256 kl: 60.7732 aux_loss: -0.4837 beta 6.73e-03\n",
      "\n",
      "Train (35 70%) elbo: -1.0015 r_loss: -0.4310 kl: 61.9979 aux_loss: -0.4679 beta 6.94e-03\n",
      "Valid (35 70%) elbo: -1.0629 r_loss: -0.4816 kl: 61.5557 aux_loss: -0.5139 beta 6.94e-03\n",
      "\n",
      "Train (36 72%) elbo: -1.0158 r_loss: -0.4369 kl: 61.1181 aux_loss: -0.4746 beta 7.14e-03\n",
      "Valid (36 72%) elbo: -1.0204 r_loss: -0.4408 kl: 61.1013 aux_loss: -0.4773 beta 7.14e-03\n",
      "\n",
      "Train (37 74%) elbo: -1.0272 r_loss: -0.4436 kl: 59.7396 aux_loss: -0.4824 beta 7.35e-03\n",
      "Valid (37 74%) elbo: -1.0719 r_loss: -0.4579 kl: 64.0535 aux_loss: -0.4780 beta 7.35e-03\n",
      "\n",
      "Train (38 76%) elbo: -1.0376 r_loss: -0.4479 kl: 58.7345 aux_loss: -0.4871 beta 7.55e-03\n",
      "Valid (38 76%) elbo: -1.0931 r_loss: -0.4745 kl: 61.4763 aux_loss: -0.5145 beta 7.55e-03\n",
      "\n",
      "Train (39 78%) elbo: -1.0441 r_loss: -0.4484 kl: 57.8454 aux_loss: -0.4907 beta 7.76e-03\n",
      "Valid (39 78%) elbo: -1.0842 r_loss: -0.4945 kl: 55.9917 aux_loss: -0.5184 beta 7.76e-03\n",
      "\n",
      "Train (40 80%) elbo: -1.0463 r_loss: -0.4508 kl: 56.2111 aux_loss: -0.4937 beta 7.96e-03\n",
      "Valid (40 80%) elbo: -0.9474 r_loss: -0.3823 kl: 54.1334 aux_loss: -0.4475 beta 7.96e-03\n",
      "\n",
      "Train (41 82%) elbo: -1.0541 r_loss: -0.4563 kl: 55.0499 aux_loss: -0.4948 beta 8.16e-03\n",
      "Valid (41 82%) elbo: -1.0798 r_loss: -0.4611 kl: 57.6461 aux_loss: -0.4936 beta 8.16e-03\n",
      "\n",
      "Train (42 84%) elbo: -1.0673 r_loss: -0.4612 kl: 54.3210 aux_loss: -0.5054 beta 8.37e-03\n",
      "Valid (42 84%) elbo: -1.0764 r_loss: -0.4922 kl: 50.8050 aux_loss: -0.5304 beta 8.37e-03\n",
      "\n",
      "Train (43 86%) elbo: -1.0764 r_loss: -0.4645 kl: 53.6820 aux_loss: -0.5059 beta 8.57e-03\n",
      "Valid (43 86%) elbo: -1.1932 r_loss: -0.5382 kl: 56.8941 aux_loss: -0.5580 beta 8.57e-03\n",
      "\n",
      "Train (44 88%) elbo: -1.0762 r_loss: -0.4636 kl: 52.3712 aux_loss: -0.5100 beta 8.78e-03\n",
      "Valid (44 88%) elbo: -1.0868 r_loss: -0.4780 kl: 51.5326 aux_loss: -0.5217 beta 8.78e-03\n",
      "\n",
      "Train (45 90%) elbo: -1.0800 r_loss: -0.4666 kl: 51.1957 aux_loss: -0.5123 beta 8.98e-03\n",
      "Valid (45 90%) elbo: -1.0985 r_loss: -0.4632 kl: 53.7117 aux_loss: -0.5101 beta 8.98e-03\n",
      "\n",
      "Train (46 92%) elbo: -1.0912 r_loss: -0.4721 kl: 50.4598 aux_loss: -0.5192 beta 9.18e-03\n",
      "Valid (46 92%) elbo: -1.1086 r_loss: -0.4610 kl: 53.0010 aux_loss: -0.5363 beta 9.18e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train (47 94%) elbo: -1.0915 r_loss: -0.4741 kl: 49.0784 aux_loss: -0.5223 beta 9.39e-03\n",
      "Epoch    46: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Valid (47 94%) elbo: -1.1365 r_loss: -0.5017 kl: 50.0021 aux_loss: -0.5513 beta 9.39e-03\n",
      "\n",
      "Train (48 96%) elbo: -1.0943 r_loss: -0.4713 kl: 48.6380 aux_loss: -0.5217 beta 9.59e-03\n",
      "Valid (48 96%) elbo: -1.1935 r_loss: -0.5265 kl: 51.1814 aux_loss: -0.5867 beta 9.59e-03\n",
      "\n",
      "Train (49 98%) elbo: -1.0972 r_loss: -0.4714 kl: 47.8514 aux_loss: -0.5235 beta 9.80e-03\n",
      "Valid (49 98%) elbo: -1.0992 r_loss: -0.4680 kl: 48.3513 aux_loss: -0.5252 beta 9.80e-03\n",
      "\n",
      "Train (50 100%) elbo: -1.1102 r_loss: -0.4794 kl: 47.1262 aux_loss: -0.5319 beta 1.00e-02\n",
      "Valid (50 100%) elbo: -1.0701 r_loss: -0.4559 kl: 46.6658 aux_loss: -0.4918 beta 1.00e-02\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use at least 50 iterations to get good results\n",
    "train(data_loader,valid_data_loader,model,optimizer,scheduler,loss_fn=nll_loss,kl_loss_fn=kl_loss_multi,n_iters=50,use_softmax=True,max_beta=1e-2,print_every=1,plot_pred=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(),\"Saved_models/HybridVAE_nll_map.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
